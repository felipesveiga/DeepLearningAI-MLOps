{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18252e19-0fc8-4f6b-a90c-1e785f7d3bd9",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1 style='font-size:40px'>  Explainable AI</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074c03f1-e6e5-44c1-a317-23d94df8b7fd",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Explainable AI</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Explainable AI é uma atividade, dentro do campo de AI, que busca pelo desenvolvimento de modelos mais interpretáveis por humanos.\n",
    "        </li>\n",
    "        <li>\n",
    "            As principais intenções dessa atividade são criar arquiteturas mais fáceis de serem debugadas, e também previsões que possa ser de alguma forma justificadas a clientes ou, até mesmo, intimações legais. \n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211fb3c-0417-4747-b226-2f9cccbdf522",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <hr>\n",
    "    <h1 style='font-size:40px'>  Interpretability</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0882d82c-e466-401d-b3bf-cb85ca397197",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Model Interpretation Methods</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Exploraremos nas próximas aulas maneiras de entendermos as previsões de nossos modelos.\n",
    "        </li>\n",
    "        <li>\n",
    "            Saber como seu modelo se comporta de acordo com os inputs pode ser algo importante para se justificar uma determinada previsão (para uma área de negócio, ou, até, legalmente). \n",
    "        </li>\n",
    "        <li>\n",
    "            Além disso, pode nos facilitar com possíveis debugs, em caso de comportamentos inesperados.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9157373-8323-4853-a5a0-8439e807e1f9",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <hr>\n",
    "    <h1 style='font-size:40px'>  Understanding Model Predictions</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f99f179-a358-43cc-9e90-8b166761a0a5",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Model Agnostic Methods</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Os métodos de interpretabilidade agnósticos a modelos não podem levar em consideração a arquitetura do algoritmo sob avaliação.\n",
    "        </li>\n",
    "        <li>\n",
    "            Exploraremos alguns deles nesta seção.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5507bb4b-56bf-427b-8bc5-036a4fa786f4",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Partial Dependence Plots</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Partial Dependence Plots são gráficos que denunciam o efeito de ajustarmos uma dada feature sobre as previsões da IA. \n",
    "        </li>\n",
    "        <li>\n",
    "            É um método limitado, porque pode ser usado com até 2 features. Além disso, não leva em conta colinearidade.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5225b0b8-a002-46f8-b15d-f66e184cdc65",
   "metadata": {},
   "source": [
    "<center style='margin-top:20px'> \n",
    "        <figure>\n",
    "            <img src='img/03_05_pdp_reg.png'>\n",
    "            <figcaption>PDP de um modelo de regressão</figcaption>\n",
    "        </figure>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a029fc04-1030-4cbc-a734-ac33d35fe5aa",
   "metadata": {},
   "source": [
    "<center style='margin-top:20px'> \n",
    "        <figure>\n",
    "            <img src='img/03_05_pdp_clas.png'>\n",
    "            <figcaption>PDP de um modelo de classificação</figcaption>\n",
    "        </figure>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ccc983-5098-4b71-9961-9eced6af555a",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Permutation Feature Importance</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Permutation Feature Importance consiste em avaliar a performance do modelo, quando substituímos o valor de uma feature por um número aleatório.\n",
    "        </li>\n",
    "        <li>\n",
    "            As features mais impactantes são aquelas cuja distorção causa a maior piora do algoritmo.\n",
    "        </li>\n",
    "        <li>\n",
    "            No entanto, esse método também tem a limitação de considerar as features independentes.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef6a34b-943c-4994-8d30-93e59a71336b",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Shapley Values</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            O Shapley Value é uma estimativa do impacto de cada feature sobre a previsão final do modelo.\n",
    "        </li>\n",
    "        <li>\n",
    "            Seu procedimento é comparar a previsão de uma instância com o valor médio estimado pelo modelo no batch.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af198bb-d760-451e-8345-05e3b01eceae",
   "metadata": {},
   "source": [
    " <center style='margin-top:20px'>\n",
    "                <img src='img/03_05_shapley_table.png'>\n",
    "            </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1290a5-2fc9-4d0c-82bc-174f7d2b7fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "03_05_shapley_table.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b8a4c75-197e-4e86-9366-9abfd53ed920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 207c33c] Continuar do Reading (Permutation Feeature Importance)\n",
      " 10 files changed, 116 insertions(+), 15 deletions(-)\n",
      " create mode 100644 img/03_05_pdp_clas.png\n",
      " create mode 100644 img/03_05_pdp_reg.png\n",
      " delete mode 100644 resources/NIPS-1989-optimal-brain-damage-Paper.pdf:Zone.Identifier\n",
      " delete mode 100644 resources/concept-drift-detection-unlabeled-data.pdf:Zone.Identifier\n",
      " delete mode 100644 resources/explaining-harnessing-adversarial-examples.pdf:Zone.Identifier\n",
      " delete mode 100644 resources/knowledge_distillation.pdf:Zone.Identifier\n",
      " delete mode 100644 resources/pipe-dream.pdf:Zone.Identifier\n",
      " delete mode 100644 resources/the-lottery-ticket-hypothesis.pdf:Zone.Identifier\n",
      "Enumerating objects: 13, done.\n",
      "Counting objects: 100% (13/13), done.\n",
      "Delta compression using up to 24 threads\n",
      "Compressing objects: 100% (8/8), done.\n",
      "Writing objects: 100% (8/8), 48.07 KiB | 48.07 MiB/s, done.\n",
      "Total 8 (delta 4), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (4/4), completed with 4 local objects.\u001b[K\n",
      "To https://github.com/felipesveiga/DeepLearningAI-MLOps.git\n",
      "   97a4d3c..207c33c  master -> master\n"
     ]
    }
   ],
   "source": [
    "! git add .\n",
    "! git commit -am 'Ver SHapley Additive Explanations'\n",
    "! git push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eea98a-8167-450d-9401-a155b940e5ae",
   "metadata": {},
   "source": [
    "<p style='color:red'> Vi do Reading (Permutation Feature Importance) até Shapley Values; Ver SHapley Additive Explanations\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
