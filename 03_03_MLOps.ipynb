{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e81c216-3098-466f-9efb-b4132a7ecef3",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1 style='font-size:40px'> High-Performance Modeling</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c502e6ad-5c55-49cd-8e20-907bf085671b",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Distributed Training</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Treinamento distribuído consiste em fittar o se modelo, distribuindo seus componentes em diferentes hardwares a fim de aprimorar a velocidade de treinamento.\n",
    "        </li>\n",
    "        <li>\n",
    "            É possível tanto distribuir o seu dataset, quanto partes do modelo.\n",
    "        </li>\n",
    "        <li>\n",
    "            Nesta aula, vamos nos concentrar mais em data parallelism.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8a6998-fa30-49e1-8676-b9e678a97e3e",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'>Distributed Training Using Data Parallelism</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Data Parallelism consiste em treinar cópias de seu modelo com um determinado pedaço de seu dataset em cada worker disponível.\n",
    "        </li>\n",
    "        <li>\n",
    "            Podemos proceder essa metodologia de duas maneiras:\n",
    "            <ul>\n",
    "                <li>\n",
    "                    <i>Treinamento Síncrono</i>: Ao final de cada época, os modelos devem compartilhar entre si as suas atualizações de parâmetros, a fim de criarem o modelo da próxima iteração.\n",
    "                </li>\n",
    "                <li> \n",
    "                        <i>Treinamento Assíncrono</i>: Deixamos os modelos treinando independentemente em cada worker para os convergirmos num único só apenas após o fitting. Pode apresentar menor acurácia, apesar de sua maior velocidade\n",
    "                </li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>\n",
    "            Observe que Data Parallelism requer que cada worker tenha espaço o bastante para comportar a cópia de seu modelo!\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f241ee-1d04-433c-b8f0-fe58f5e8380a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2 style='font-size:30px'> High-Performance Ingestion</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            A eficiência das transformações de dados é um fator sutil que pode aprimorar o tempo de treinamento e inferência de uma IA.\n",
    "        </li>\n",
    "        <li>\n",
    "            Enquanto uma época é rodada, podemos configurar nossa CPU para processar o próximo batch. Assim, a GPU poderá iniciar a próxima iteração, sem precisar aguardar o processamento dessa coleção de dados.   \n",
    "        </li>\n",
    "        <li>\n",
    "            Quando nossos inputs se encontram na nuvem, a leitura de um único arquivo pode demorar, por questões de rede. Para evitar que o fluxo tenha que aguardar o download do arquivo em cada iteração, podemos paralelizar o download de múltiplas fontes. \n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb21ce0c-c5fb-488a-96a2-1d2c4012e2ea",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Training Large Models - The Rise of Giant Neural Nets and Parallelism</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            No momento atual, o crescimento de memória das placas de vídeo não está acompanhando o crescimento do tamanho de IA's. Nesse contexto, o treinamento de arquiteturas profundas requer algumas estratégias para garantir que não haverá ausência de memória.\n",
    "        </li>\n",
    "        <li>\n",
    "            Model e Data Parallelisms podem ser boas abordagens no gerenciamento efetivo de hardware no treinamento desses modelos. No entanto, eles têm margem para melhoria. Uma abordagem interessante seria fazer o Pipeline Parallelism.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f9add9-4712-4029-98bf-df62f83cf37f",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Pipeline Parallelism</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Model Parallelism tem a ineficiência de uma GPU ficar ociosa, quando encaminha seus resultados à próxima. \n",
    "        </li>\n",
    "        <li>\n",
    "            Em Pipeline Parallelism, evitamos isso dividindo o nosso batch de instâncias em micro-batches. Dessa forma, uma vez que a GPU terminar de processar um micro-batch, poderá iniciar suas computações sobre o próximo. \n",
    "            <center style='margin-top:20px'>\n",
    "                <img src='img/03_03_pipe_parallelism.png'>\n",
    "            </center>\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b183a0-c3d3-46f3-8709-b7e4ffabc911",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <hr>\n",
    "    <h1 style='font-size:40px'> Knowledge Distillation</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b766e23-0a6d-4db7-86dc-276eefad5a25",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Quando um modelo for grande demais para ser empregado no ambiente de produção, podemos tentar \"extrair\" o seu conhecimento adquirido e implantá-lo em modelos mais simples. Essa metodologia é conhecida como \"Knowledge Distillation\".\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5233b14c-ff1f-4e8c-bd29-717f85ddca82",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'>  Teacher and Student Networks</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Uma forma de destilar conhecimentos seria treinar modelos menores \"students\", tendo como referência o modelo maior \"teacher\".            \n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c120e3-b414-4232-b6e6-ab150f0908d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "03_03_pipe_parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e4a0ce6-d662-42ea-88df-5802d9d574f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "[master f7c1797] Fazer Lab do Vertex AI\n",
      " 5 files changed, 243 insertions(+), 111 deletions(-)\n",
      " create mode 100644 03_03_MLOps.ipynb\n",
      " create mode 100644 img/03_03_pipe_parallelism.png\n",
      " create mode 100644 resources/pipe-dream.pdf\n",
      " create mode 100644 resources/pipe-dream.pdf:Zone.Identifier\n",
      "Enumerating objects: 12, done.\n",
      "Counting objects: 100% (12/12), done.\n",
      "Delta compression using up to 24 threads\n",
      "Compressing objects: 100% (8/8), done.\n",
      "Writing objects: 100% (8/8), 461.23 KiB | 35.48 MiB/s, done.\n",
      "Total 8 (delta 4), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (4/4), completed with 4 local objects.\u001b[K\n",
      "To https://github.com/felipesveiga/DeepLearningAI-MLOps.git\n",
      "   b8e2976..f7c1797  master -> master\n"
     ]
    }
   ],
   "source": [
    "! git add .\n",
    "! git commit -am 'Ver Knowledge Distillation Techniques'\n",
    "! git push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feedfac7-7d86-4414-a921-8d2505c59cbb",
   "metadata": {},
   "source": [
    "<p style='color:red'> Fiz o Lab; Ver Knowledge Distillation Techniques\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
