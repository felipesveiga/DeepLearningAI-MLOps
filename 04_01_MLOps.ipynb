{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3072dec-0b91-4215-9bbb-0760d71524c2",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1 style='font-size:40px'>  Introduction to Model Serving</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fbf31c-ad36-4302-8e84-cc5e510ddf05",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Course Overview</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            O último curso da especialização é voltado ao ensinamento de técnicas e melhores práticas de implantações de modelos de ML.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c8ccb5-3353-4277-9d05-d785f1a9dad5",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Introduction to Model Serving</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Ao se realizar o deploy de um algoritmo, os Engenheiros de ML devem se preocupar com a modalidade de inferência dos modelos (real-time ou batch), assim como o equilíbrio entre latência e throughput com custos. \n",
    "        </li>\n",
    "        <li>\n",
    "            No caso das questões de infra, costuma-se recorrer ao compartilhamento de GPU's e deploy multi-modelos, a fim de assegurarmos bons throughput e latência e economia de custos.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa807d5-4a13-49f9-9960-64199ca58d6b",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1 style='font-size:40px'> Introduction to Model Serving Infrastructure</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b7b85a-1287-436f-80ab-82c31bdb18b1",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Introduction to Model Serving Infrastructure</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            A escolha do modelo ideal para implantação envolve muito mais do que somente a sua performance. O algoritmo também deve ser capaz de responder rapidamente suas requisições (real-time) e de caber na infraestrutura tida. \n",
    "        </li>\n",
    "        <li>\n",
    "            O instrutor sugere definirmos os critérios de infra e latência, antes da fase de modelagem. Assim, o Cientista será capaz de criar seus modelos orientado às restrições impostas, evitando surpresas no momento de deployment.\n",
    "        </li>\n",
    "        <li>\n",
    "            Outro ponto válido de se mencionar é que as requisições de nossos clientes podem não conter todos os dados necessários para a previsão do modelo. Nessa situação, é importante a existência de um fluxo de alta performance capaz de fazer os JOIN's necessários em um curto período de tempo.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6168803a-ba1d-4514-8602-18ddf5cc0d7f",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Deployment Options</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Em situações em que há uma demanda por baixíssima latência (IoT), a implantação do modelo em edge device torna-se uma opção.\n",
    "        </li>\n",
    "        <li>\n",
    "            No entanto, lembre-se: dispositivos como celulares e veículos Não têm o mesmo poder computacional que servidores. Por isso, seu modelo deverá ter uma arquitetura menos complexa. Ainda assim, é preferível que a IA não consuma a totalidade dos recursos disponíveis, pois podem haver outros processos importantes que dependam deles. \n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
