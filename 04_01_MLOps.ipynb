{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3072dec-0b91-4215-9bbb-0760d71524c2",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1 style='font-size:40px'>  Introduction to Model Serving</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fbf31c-ad36-4302-8e84-cc5e510ddf05",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Course Overview</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            O último curso da especialização é voltado ao ensinamento de técnicas e melhores práticas de implantações de modelos de ML.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c8ccb5-3353-4277-9d05-d785f1a9dad5",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Introduction to Model Serving</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Ao se realizar o deploy de um algoritmo, os Engenheiros de ML devem se preocupar com a modalidade de inferência dos modelos (real-time ou batch), assim como o equilíbrio entre latência e throughput com custos. \n",
    "        </li>\n",
    "        <li>\n",
    "            No caso das questões de infra, costuma-se recorrer ao compartilhamento de GPU's e deploy multi-modelos, a fim de assegurarmos bons throughput e latência e economia de custos.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa807d5-4a13-49f9-9960-64199ca58d6b",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1 style='font-size:40px'> Introduction to Model Serving Infrastructure</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b7b85a-1287-436f-80ab-82c31bdb18b1",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Introduction to Model Serving Infrastructure</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e2e34e3-f9c9-4d82-be15-3f77a108e5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 1c24b3e] Concluir os readings da seção\n",
      " 1 file changed, 32 insertions(+), 20 deletions(-)\n",
      "Enumerating objects: 5, done.\n",
      "Counting objects: 100% (5/5), done.\n",
      "Delta compression using up to 24 threads\n",
      "Compressing objects: 100% (3/3), done.\n",
      "Writing objects: 100% (3/3), 968 bytes | 968.00 KiB/s, done.\n",
      "Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
      "To https://github.com/felipesveiga/DeepLearningAI-MLOps.git\n",
      "   4f5c238..1c24b3e  master -> master\n"
     ]
    }
   ],
   "source": [
    "! git add .\n",
    "! git commit -am 'Introduction to Model Serving Infrastructure'\n",
    "! git push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2268c32f-babb-4ea7-ac18-24ba9bfa5820",
   "metadata": {},
   "source": [
    "<p style='color:red'> Iniciei curso 4; Ver Introduction to Model Serving Infrastructure\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
