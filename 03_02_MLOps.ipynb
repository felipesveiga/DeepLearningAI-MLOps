{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c953c61-623d-46dc-8f26-f09dab02e361",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1 style='font-size:40px'> Dimensionality Reduction</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1474b1a9-a5eb-4aa1-93e1-7a1be0d6d145",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Dimensionality Effect on Performance</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Foi demonstrado nessa aula que utilizar datasets de dimensões exageradas pode levar ao overfitting dos modelos. Isso porque os algoritmos tenderão a capturar padrões muito particulares dos dados de treinamento, o que danificará a sua capacidade de generalização.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8121bfc7-fbd3-40c7-861c-ce67645da843",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2 style='font-size:30px'> Curse of Dimensionality</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Além de aumentar o risco de overfitting, a expansão horizontal do dataset faz com que os data points tendam a possuir mesmas distâncias entre si. Com isso, algortimos baseados em distância, como KNN e K-Means, podem ter problemas em discerni-los.\n",
    "        </li>\n",
    "        <li>\n",
    "            Também é válido mencionar que o acréscimo de features sem a adição de novas instâncias fará com que o espaço se torne cada vez mais esparso.\n",
    "        </li>\n",
    "        <li>\n",
    "            Esse fenômeno é nomeado como Curse of Dimensionality.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9dd4f3-373b-433c-87fd-8a5aeac34e2f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2 style='font-size:30px'> Algorithmic Dimensionality Reduction</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            No decorrer dos anos, foram desenvolvidas metodologias de redução de dimensionalidade dos datasets. Os mais famosos em Ciência de Dados seriam o PCA e t-SNE. \n",
    "        </li>\n",
    "        <li>\n",
    "            Alguns outros algoritmos que merecem menção são:\n",
    "            <ul> \n",
    "                <li>\n",
    "                    <i> Linear Discriminant Analysis:</i> Especializado em classificações. Propõe criar uma representação em uma dimensionalidade menor, maximizando as distâncias entre as classes.\n",
    "                </li>\n",
    "                <li> \n",
    "                    <i> Partial Least Squares:</i> Especializado em regressões. Cria uma projeção que maximiza a correlação entre o $y$ e o $X$ do novo espaço.\n",
    "                </li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c002a948-23c4-4019-8356-5cf2d5f20ec9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2 style='font-size:30px'> Principal Components Analysis</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "             Maximiza a variância das projeções, ao mesmo tempo em que minimiza o erro de reconstrução ao quadrado.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>\n",
    "<center style='margin-top:20px'> \n",
    "    <img src='img/03_02_pca.png'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e4c878-8e66-4097-9fb0-f0c83f01acc4",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Other Techniques</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "             Vamos conferir mais algumas técnicas de redução de dimensionalidade.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa7356e-77b4-4dd3-8b86-e48fb3b537ed",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Independent Component Analysis (ICA)</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Busca por direções no espaço que são mais estatisticamente independentes.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ed9a17-0c48-4c84-ba26-cb3428106d26",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Non-negative Matrix Factorization (NMF)</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Algoritmo interpretável.\n",
    "        <li> \n",
    "            Requer que os componentes da matriz sejam não negativos.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d1ce07-7edd-4cfc-9762-f90d695b4496",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <hr>\n",
    "    <h1 style='font-size:40px'> Quantization and Pruning</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7f7df4-f151-455c-890f-98383d07ff55",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Mobile, IoT, and Similar Use Cases</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "             Em algumas áreas da economia, como a indústria, existe a tendência de se implantar modelos de ML nos produtos fabricados. Como esses aparelhos não têm poder computacional tão vasto, os Cientistas de Dados são obrigados a utilizar algoritmos mais simples.\n",
    "        </li>\n",
    "        <li>\n",
    "            A implantação da IA on-device proporciona menores custos aos fabricantes - não precisa de Cloud Computing -, além de conformidade a legislações de privacidade do usuário.\n",
    "        </li>\n",
    "        <li>\n",
    "            Segue abaixo um paralelo entre o deploy em Cloud e local de IA's.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08379f03-a8fa-4266-bf36-41665bf9197d",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Inference on the Cloud</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            O uso do modelo na nuvem possibilita o consumo de arquiteturas mais poderosas, além da utilização de escalabilidade.\n",
    "        </li>\n",
    "        <li>\n",
    "            Vale lembrar que a atualização da IA depende apenas de sua modificação no servidor, e não de upgrade do app ou compra de novo aparelho pelo cliente.\n",
    "        </li>\n",
    "        <li>\n",
    "            No entanto, o consumo da IA fica dependente da internet. O UX pode ser prejudicado, caso haja conexões mais lentas.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea2b143-d3a4-4b7e-8fb3-f74f38a1be06",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Inference on the Device</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Apesar de necessitar de arquiteturas mais simples, o tempo de resposta da IA não estará mais sujeito à qualidade da internet. \n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febbcb76-f2c8-4b99-b499-636971f3ab93",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'>  Benefits and Process of Quantization</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            A quantização de um modelo consiste em reduzir a precisão dos seus parâmetros.\n",
    "        </li>\n",
    "        <li>\n",
    "            Seus principais benefícios são a redução do espaço ocupado pelo arquivo da IA, e do tempo de inferência\n",
    "        </li>\n",
    "        <li>\n",
    "            Por incrível que pareça, a acurácia do modelo não se degradará, necessariamente.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504e7140-c12c-4df3-b3b7-ea8063e4b00b",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'>  Post Training Quantization</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            A quantização pós-treinamento consiste em tratar os parâmetros da IA consolidada.\n",
    "        </li>\n",
    "        <li>\n",
    "            Existem diversas abordagens de quantização de redes neurais:\n",
    "            <center style='margin-top:20px'>\n",
    "                <img src='img/03_02_quant_strategies.png'>\n",
    "            </center>\n",
    "        </li>\n",
    "        <li style='margin-top:20px'>\n",
    "            Podemos, até mesmo, quantizar a IA de modo que os parâmetros passem a ser representados por integers\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d15164a-dc02-4397-89d5-a4c2e2da3222",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'>  Quantization Aware Training</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            E possível também quantizarmos a IA em treinamento. No forward pass, arredondamos os floats de acordo com o método desejado.\n",
    "        </li>\n",
    "        <li>\n",
    "            O resultado esperado é a criação de coeficientes mais robustos à quantização. \n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eb8dae-363a-47d3-9251-dd9c3f24bd30",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Pruning</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Uma outra maneira de diminuirmos o tamanho de nossa NN seria descartando determinados coeficientes - setar como 0. A maneira mais comum de se fazer isso seria desconsiderando os parâmetros de menor magnitude.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee1e2a2-ea7c-4d25-9fb6-faf9fbea5fc3",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Optimal Brain Damage</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            O paper \"Optimal Brain Damage\", desenvolvido por Yann LeCun, propôs avaliar a importância de um coeficiente, avaliando a alteração da sua loss ao acrescentarmos uma pertubação aleatória em seu valor. \n",
    "        </li>\n",
    "        <li>\n",
    "            Quanto menor a alteração, menos importante era o coeficiente, na visão dos pesquisadores.\n",
    "        </li>\n",
    "        <li>\n",
    "            Uma vez podada a IA, tentava-se aplicar um fine-tuning sobre ela, o que se mostrou algo desafiador.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d9fa91-c268-45a5-a370-970f93e6d010",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            A solução para esse problema surgiu em 2019, em \"The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks\". A publicação sugeriu que todo MLP possui uma sub-NN capaz de atingir o mesmo desempenho que o modelo pleno. \n",
    "        </li>\n",
    "        <li>\n",
    "            Uma vez encontrada essa sub-net, como no caso de LeCun, é sugerido reinicializar os seus coeficientes e retreiná-la.\n",
    "        </li>\n",
    "        <li>\n",
    "            No entanto, os autores afirmam ser difícil o encontro da arquitetura-ótima em redes muito grandes.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7711b60b-adc5-4e26-a91b-bf179e61984d",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <hr>\n",
    "    <h1 style='font-size:40px'> Dimensionality Reduction</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80de36dd-12e1-47ed-869a-a2d43f662f42",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Distributed Training</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Treinamento distribuído consiste em fittar o se modelo, distribuindo seus componentes em diferentes hardwares a fim de aprimorar a velocidade de treinamento.\n",
    "        </li>\n",
    "        <li>\n",
    "            É possível tanto distribuir o seu dataset, quanto partes do modelo.\n",
    "        </li>\n",
    "        <li>\n",
    "            Nesta aula, vamos nos concentrar mais em data parallelism.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed55a00-eed5-4e5f-b1bd-99362ed733a8",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'>Distributed Training Using Data Parallelism</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Data Parallelism consiste em treinar cópias de seu modelo com um determinado pedaço de seu dataset em cada worker disponível.\n",
    "        </li>\n",
    "        <li>\n",
    "            Podemos proceder essa metodologia de duas maneiras:\n",
    "            <ul>\n",
    "                <li>\n",
    "                    <i>Treinamento Síncrono</i>: Ao final de cada época, os modelos devem compartilhar entre si as suas atualizações de parâmetros, a fim de criarem o modelo da próxima iteração.\n",
    "                </li>\n",
    "                <li> \n",
    "                        <i>Treinamento Assíncrono</i>: Deixamos os modelos treinando independentemente em cada worker para os convergirmos num único só apenas após o fitting. Pode apresentar menor acurácia, apesar de sua maior velocidade\n",
    "                </li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>\n",
    "            Observe que Data Parallelism requer que cada worker tenha espaço o bastante para comportar a cópia de seu modelo!\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2fff0d-4b83-49f8-8405-f17ca2560421",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2 style='font-size:30px'> High-Performance Ingestion</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            A eficiência das transformações de dados é um fator sutil que pode aprimorar o tempo de treinamento e inferência de uma IA.\n",
    "        </li>\n",
    "        <li>\n",
    "            Enquanto uma época é rodada, podemos configurar nossa CPU para processar o próximo batch. Assim, a GPU poderá iniciar a próxima iteração, sem precisar aguardar o processamento dessa coleção de dados.   \n",
    "        </li>\n",
    "        <li>\n",
    "            Quando nossos inputs se encontram na nuvem, a leitura de um único arquivo pode demorar, por questões de rede. Para evitar que o fluxo tenha que aguardar o download do arquivo em cada iteração, podemos paralelizar o download de múltiplas fontes. \n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9c7b24-178c-47ab-9cc9-4c917d620e06",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Training Large Models - The Rise of Giant Neural Nets and Parallelism</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            No momento atual, o crescimento de memória das placas de vídeo não está acompanhando o crescimento do tamanho de IA's. Nesse contexto, o treinamento de arquiteturas profundas requer algumas estratégias para garantir que não haverá ausência de memória.\n",
    "        </li>\n",
    "        <li>\n",
    "            Model e Data Parallelisms podem ser boas abordagens no gerenciamento efetivo de hardware no treinamento desses modelos. No entanto, eles têm margem para melhoria. \n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0d63ef-b315-43d9-af42-2cd26c38c66e",
   "metadata": {},
   "source": [
    "<p style='color:red'> Vi High-Performance Ingestion e iniciei Training Large Models - The Rise of Giant Neural Nets and Parallelism; Training Large Models - The Rise of Giant Neural Nets and Parallelism\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
