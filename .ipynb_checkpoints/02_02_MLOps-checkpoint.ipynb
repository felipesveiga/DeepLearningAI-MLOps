{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcb89514-7e9a-475d-a96f-1ec38785fa61",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px'> Feature Engineering</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dbeec6-b76b-4893-bfcd-85b1ce765f02",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Introduction to Preprocessing</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>   \n",
    "            O pré-processamento é uma etapa vital da cadeia de ML. Envolve procedimentos como a numeralização do dataset, normalização e redução da dimensionalidade dos dados.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f80f2ae-3a53-40ce-98c7-242e014ef2f9",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Art of Feature Engineering</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Feature Engineering consiste na transformação de nosso dataset, visando viabilizar/facilitar o treinamento de nosso modelo. Isso pode ocorrer, seja pela combinação de features (Polynomial, PCA), seja pela adição de novas features no dataset.\n",
    "        </li>\n",
    "        <li>\n",
    "             A modificação das propriedades estatísticas de features já existentes (padronização) também é considerada uma feature engineering.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1415d570-b807-43dc-be20-064adb24d9dc",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Preprocessing Operations</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>   \n",
    "               Crowe apenas nos deu uma revisão sobre os principais tratamentos que devemos aplicar sobre os nossos dados.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb2e0a-ecca-4e00-963a-855b9f09e59d",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'>Feature Engineering Techniques </h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>   \n",
    "            Vamos entrar no detalhe de algumas das principais técnicas para Feature Engineering.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580883cb-3605-4a4e-98ee-fb0026b530e1",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Min-Max Scaling</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Chamado no curso como <i> normalization</i>, é recomendado quando sabemos que nossos dados não são gaussianos.\n",
    "            <center style='margin-top:20px'> \n",
    "                $X_{\\text{min-max}}=\\frac{X-X_{\\text{min}}}{X_{\\text{max}}-X_{\\text{min}}}$\n",
    "            </center>\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97f4c17-1b18-4085-91d3-6fb98b319d5f",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Standardization</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Adequado para quando possuímos distribuições gaussianas.\n",
    "            <center style='margin-top:20px'> \n",
    "                $X^{'}=\\frac{X-\\mu}{\\sigma}$\n",
    "            </center>\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c513f9a9-c7ec-4a44-b5f9-d6fdc9430ffe",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Bucketizing</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Consiste em criar categorias para as suas features numéricas, com base no intervalo ao qual elas pertencem (`pd.cut`).\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009c7775-d8ea-4a1c-a789-10f629b65e26",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Dimensionality Reduction</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Importante para reduzir a carga computacional do treinamento dos algoritmos, e também para conseguimos imaginar a distribuição das instâncias pelo espaço.\n",
    "        </li>\n",
    "        <li>\n",
    "            PCA, t-SNE, Uniform Manifold Approximation and Projection (UMAP).\n",
    "        </li>\n",
    "        <li>\n",
    "            Procure pelo TensorFlow Embedding Projector, caso queira experimentar essas diversas técnicas em seus dados.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0655f3b8-03aa-445a-b642-868bfc597ff9",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Feature Crosses</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>   \n",
    "            Feature Cross consiste em combinar diversas features em uma única. Podemos fazer isso multiplicando os valores das colunas (Polynomial), por exemplo.\n",
    "        </li>\n",
    "        <li>\n",
    "            Isso não é a mesma coisa que aplicar os algoritmos de redução de dimensionalidade vistos.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fca38fc-90f6-4f51-b6b3-9778a1693662",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <hr>\n",
    "    <h1 style='font-size:40px'> Feature Transformation at Scale</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05b0f31-c32c-455c-8577-fa1de04d4b07",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Preprocessing Data at Scale</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>   \n",
    "            Quando lidamos com enormes quantias de dados, o ritual para a elaboração do projeto pode ser um pouco diferente com relação a projetos mais casuais.\n",
    "        </li>\n",
    "        <li>\n",
    "            Uma prática comum é trabalhar toda a Pipeline de transformação sobre uma amostra dos dados em um notebook, para depois reproduzi-la com o framework de Big Data. \n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d2794f-471b-4a5f-b54b-14e1cc867658",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Inconsistencies in Feature Engineering</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Em alguns casos, o ETL do ambiente de desenvolvimento não é o mesmo do de produção - seja por alguma obrigatoriedade, seja por desorganização. Isso eleva os riscos de haver inconsistências entre as feature engineerings dessas etapas.\n",
    "        </li>\n",
    "        <li>\n",
    "            Para evitar que isso aconteça, esteja sempre atento a cada transformação realizada na Pipeline oficial. Caso o contrário, seu modelo provavelmente alcançará performances abaixo do esperado!\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e31285-203e-4197-873e-64cb12bd750f",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Why Transform per Batch?</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Em aplicações de Big Data, podemos acelerar as transformações de nossos dados recorrendo a manipulações per-batch (assim como a Batch Normalization, de redes neurais).\n",
    "        </li>\n",
    "        <li>\n",
    "            Em treinamento, poderíamos extrair as estatísticas necessárias, baseando-se apenas no batch. Quando formos para produção, o tratamento dos dados poderia acontecer com a média exponencial das estatísticas extraídas.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c25176e-1a3c-4369-b650-9eb80692d22c",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Optimizing Transformations</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Como as transformações normalmente ocorrem em ambiente de nuvem, precisamos escolher a forma mais eficiente de utilizarmos a infra disponível para redução de custos.  \n",
    "        </li>\n",
    "        <li>\n",
    "            No contexto de Deep Learning, o ETL é feito pelo processador. Para evitar que a GPU fique ociosa nesse período de transformações, você pode programar um prefetch.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0af0a0e-d8d9-4fa0-8b07-1cd75d224c73",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> TensorFlow Transform</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>   \n",
    "            Somos apresentados aqui ao `tf.transform`, pacote TensorFlow voltado à automatização do pré-processamento de dados e treinamento de modelos.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5848ba07-b00b-44c2-ba62-aba1fc093f5f",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Esquematização do `tf.transform`</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            O tf.transform inicia sua jornada fazendo um train-test-split na etapa de Example Gen. Logo em seguida, coleta estatísticas sobre os dados em Statistics Gen e cria um schema para o dataset em Schema Gen.\n",
    "        </li>\n",
    "        <li>\n",
    "            A etapa Transform é onde as feature engineerings acontecem. Uma vez feito isso, encaminhamos os dados aos outros componentes do TFX.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e742cfe-b73e-4804-bfd3-e64e46dc0b6a",
   "metadata": {},
   "source": [
    " <center style='margin-top:20px'> \n",
    "                <img src='img/02_02_tf_transform.png'>\n",
    "            </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f2f856-5f11-4d21-94af-5a248cd2e481",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Etapa de Transform</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Em Transform, codificamos todas as manipulações desejadas. Essa etapa retornará os dados transformados, junto com um TensorFlow Graph que informa todas as transformações aplicadas.\n",
    "        </li>\n",
    "        <li>\n",
    "            Esse grafo armazenará toda a lógica das transformações necessárias. Em deployment, ele poderá ser utilizado para transformar os dados produtivos, independentemente do ambiente (tf.lite, tf.mobile...) \n",
    "        </li>\n",
    "        <li>\n",
    "            Uma vez transformados os dados, treinamos nosso modelo em Trainer. Isso gerará um outro grafo que, combinado com o de transformação, comporão a pipeline completa de nosso sistema de IA.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680a53a9-7181-431d-ba7c-165756098c11",
   "metadata": {},
   "source": [
    " <center style='margin-top:20px'> \n",
    "                <img src='img/02_02_tf_transform_pipe.png'>\n",
    "            </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33dbfbe-90f0-483c-bd9e-0c7c3788f809",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'>  Analyzers</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Os Analyzers são entidades que analisam nosso set de treino, extraindo as informações/estatísticas necessárias para cada transformação.\n",
    "        </li>\n",
    "        <li>\n",
    "            Por exemplo, o Analyzer de TF-IDF computará as frequências de cada token do set.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee509f09-eedc-42c2-9e10-b89c246c29f3",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Hello World with tf.Transform</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>   \n",
    "            Somos apresentados aqui a um pequeno exemplo de uso do tf.Transform.\n",
    "        </li>\n",
    "        <li>\n",
    "            Podemos programar todo o preprocessamento em uma função. Tendo-a fitado, deveremos passá-la como argumento da função `tft_beam.AnalyzeAndTransformDataset`, dentro de um contexto.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48463f6a-03c7-4df2-844d-d7abbe316d8d",
   "metadata": {},
   "source": [
    "<center style='margin-top:20px'> \n",
    "    <figure>\n",
    "        <img src='img/02_02_tft_beam_syntax.png'>\n",
    "        <figcaption> Nessa sintaxe especial, `(raw_data, raw_data_metadata)` é sinalizado como input do que está à direita do Pipe. O produto da transformação será a tupla `transformed_dataset, transform_fn`. </figcaption>\n",
    "    </figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bcd63d-ddce-45e0-aa98-c233143cb376",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <hr>\n",
    "    <h1 style='font-size:40px'> Feature Selection</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e3eba2-826f-4195-8d15-d8685eebe2e6",
   "metadata": {},
   "source": [
    "<p style='color:red'> Terminei o lab e quiz; Feature Spaces </p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
