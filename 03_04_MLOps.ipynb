{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a84f0a1b-454b-496f-a465-c9c02a0122e5",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1 style='font-size:40px'> Model Analysis Overview</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97b55f2-fad8-41d4-99dd-dddcc9ee4ff9",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'>  Model Performance Analysis</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Podemos analisar o desempenho de nosso modelo de duas maneiras. A primeira, mais recorrente, seria verificando as suas métricas qualitativas - black box. A outra, mais detalhista, seria com o monitoramento das computações - model intropection.\n",
    "        </li>\n",
    "        <li>\n",
    "            No monitoramento black box, seria interessante estudar o desempenho do modelo sobre vários segmentos de seu dataset, a fim de garantir sua fairness.\n",
    "        </li>\n",
    "        <li>\n",
    "            Um exemplo de model introspection seria a análise da magnitude dos coeficientes de um mecanismo de atenção.  \n",
    "            <center style='margin-top:20px'>\n",
    "                <img src='img/03_04_attention.png'>\n",
    "            </center>\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9324b77c-dd61-4153-a36f-8e7d2b780ab9",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <hr>\n",
    "    <h1 style='font-size:40px'> Advanced Model Analysis and Debugging</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415f3c0e-fac5-4f21-9f09-d71b2c3345cc",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Introduction to TensorFlow Model Analysis</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            O TensorFlow Model Analysis (TFMA) é uma ferramenta voltada a análises black-box de uma rede neural TF.\n",
    "        </li>\n",
    "        <li>\n",
    "            A lib consegue, automaticamente, validar o seu modelo treinado sobre diferentes seções de seu dataset, buscando por anomalias.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf014a1-f038-41ea-a182-a4759bdf9544",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Benchmark Models</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Modelos de benchmark são algoritmos simples utilizados como baseline em projetos de Ciência de Dados.\n",
    "        </li>\n",
    "        <li>\n",
    "            Seu papel é oferecer uma estimativa de desempenho mínimo esperado para a tarefa em questão.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febb0c42-d899-41bb-9ae5-c8fbe6bec9c0",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Sensitivity Analysis and Adversarial Attacks</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            A análise de sensibilidade busca estudar o efeito da modificação dos dados de input sobre as previsões do modelo. Nela, avaliamos as diferenças dos outputs da IA, quando aplicamos modificações sutis sobre nossos dados.\n",
    "        </li>\n",
    "        <li>\n",
    "            Esse monitoramento pode denunciar quais features têm mais relevância na previsão do modelo.\n",
    "        </li>\n",
    "        <li>\n",
    "            Por sua vez, Adversarial Attacks consistem em abordagens a nossos modelos a fim de extrair informações de suas previsões para fins maliciosos.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb38837-22fa-4880-87d4-ca98f7156203",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Sensitivity Analysis Methods</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c48e6a-f4d9-4928-9ed0-49482933b1f8",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Random Attacks</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Random Attacks consistem em fornecer dados aleatorizados para previsão. Sua principal vantagem é a captura de possíveis bugs de software na pipeline de modelagem (divisão por 0, por exemplo).\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22231df-966d-4601-be2c-8d5da4850a77",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'>Partial Dependence Plots</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            São gráficos que denunciam o efeito quantitativo sobre as previsões causado por mudanças em cada uma de suas features.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e872cfbb-7a76-47e1-af98-6ebab57a9d0c",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Adversarial Attacks Modalities</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0534782a-84ef-4ed5-874b-0a3771211836",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Informational Harm</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Informational Harm contempla uma série de abordagens feitas a nosso modelo, a fim de se obter dados sensíveis. \n",
    "        </li>\n",
    "        <li>\n",
    "            Por exemplo, já foram criadas metodologias que conseguem definir se dados de uma certa pessoa estavam na base de treinamento, apenas com a análise de previsões. Já foi demonstrado também como construir uma réplica de uma IA, com o estudo de seus outputs!\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459875d4-553f-41f3-aa69-8b8bd71e1bfb",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Behavioral Harm</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Consiste na explioração da variância do modelo, com a aplicação de modificações sutis em nossos dados.\n",
    "        </li>\n",
    "        <li> \n",
    "            Isso é algo bastante comum no campo de CV. Já foi criado um experimento que aplicou pequenas mudanças sobre as imagens de input para que elas fossem previstas como um avestruz!\n",
    "        </li>\n",
    "    </ul>\n",
    "     <center style='margin-top:20px'>\n",
    "                <img src='img/03_04_ostrich.png'>\n",
    "            </center>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e4a0ce6-d662-42ea-88df-5802d9d574f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 4d9cad4] Introduction to TensorFlow Model Analysis\n",
      " 4 files changed, 2622 insertions(+), 12 deletions(-)\n",
      " create mode 100644 assignments/03_04/C3_W4_Lab_1_TFMA.ipynb\n",
      " create mode 100644 assignments/03_04/C3_W4_Lab_2_TFX_Evaluator.ipynb\n",
      " create mode 100644 img/03_04_attention.png\n",
      "Enumerating objects: 13, done.\n",
      "Counting objects: 100% (13/13), done.\n",
      "Delta compression using up to 24 threads\n",
      "Compressing objects: 100% (9/9), done.\n",
      "Writing objects: 100% (9/9), 35.46 KiB | 17.73 MiB/s, done.\n",
      "Total 9 (delta 3), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
      "To https://github.com/felipesveiga/DeepLearningAI-MLOps.git\n",
      "   44fba83..4d9cad4  master -> master\n"
     ]
    }
   ],
   "source": [
    "! git add .\n",
    "! git commit -am 'explaining-harnessing-adversarial-examples'\n",
    "! git push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a631493-8ddd-4423-ada1-3da46e510939",
   "metadata": {},
   "source": [
    "<p style='color:red'> Vi Model Debugging Overview até o Aedversarial Attack Demo; Ver Residual Analysis\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
